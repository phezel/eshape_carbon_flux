{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c919f9d5-4acc-4f37-9252-8561223ae702",
   "metadata": {},
   "source": [
    "# Read script for xCO2 data\n",
    "## NOAA Greenhouse Gas Marine Boundary Layer Reference\n",
    "\n",
    "Can be downloaded from: \n",
    "https://gml.noaa.gov/ccgg/mbl/\n",
    "(Choose 'Surface' with all dates, all latitudes to enable download of entire dataset, though plot will show only 8 years.)\n",
    "Filename of format:  co2_GHGreference.##########_surface.txt.   \n",
    "\n",
    "This file should be included with the contents of this notebook (~2.1 MB).  Download to ./data/raw/ if is not. \n",
    "\n",
    "### Notes on data file\n",
    "Data is in rows: \n",
    "  - ```decimalYear, measurement, uncertainty, measurement, uncertainty ...``` \n",
    "for each of sine latitude points given in the file.  There is only one spatial dimension: data is averaged by latitude.  \n",
    "\n",
    "Geolocation given by sineLatitude values as 'Sine of latitude steps: ' in comment/header at start of file.   These are converted to latitude values for use in these CO2 calculations. \n",
    "\n",
    "Dates are roughly every 8 days.  Nearest neighbor is used initially for corresponding time.  Proper treatment for monthly data requires interpolation by time to daily values, then averaging for each month at each latitude.  \n",
    "\n",
    "Data starts in the first row after comments/header indicated by '#' at start of each line.\n",
    "\n",
    "Data source, contacts, and citation are given in the data file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "00f1df81-a503-49f1-850b-5c3ebeb6294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import io\n",
    "import datetime\n",
    "\n",
    "import numpy as np \n",
    "import xarray as xr\n",
    "import pandas as pd \n",
    "\n",
    "from path import Path\n",
    "import regex as re\n",
    "import PyAstronomy.pyasl as pyasl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf782a2-b4d4-41bd-9dc3-98698364c177",
   "metadata": {},
   "source": [
    "## Read xCO2 data from fully documented downloaded file.  \n",
    "This file needs to be downloaded from the website  https://gml.noaa.gov/ccgg/mbl/ as instructed above.  Filename is of the format:  co2_GHGreference.##########_surface.txt, with the '#' generated at download time.  Assume in ./data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fe6d64c0-1803-414b-99d2-7c6afce77f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_xCO2_file(mblFile): \n",
    "\n",
    "    # -----\n",
    "    # find xCO2 file in ./data/raw directory\n",
    "    # look in ./data/raw directory for file named co2_GHGreference.###########_surface.txt, \n",
    "    # Get newest version of file based on filetime  \n",
    "\n",
    "    newest_file = None\n",
    "   \n",
    "    if (type(mblFile) is Path):\n",
    "        # do nothing - is only one file of correct form\n",
    "        mblFile = mblFile\n",
    "    elif (type(mblFile) is list) : \n",
    "        # get most recent - based on creation date of file (for unix is .getmtime, not .getctime)\n",
    "        # can iterate over list items \n",
    "        for kk in mblFile: \n",
    "            if ( newest_file is None or newest_file.getmtime() > kk.getmtime() ):\n",
    "                newest_file = kk\n",
    "        mblFile = newest_file \n",
    "    else:\n",
    "        raise Exception(\"Need xCO2 MBL file in ./data/raw/  of form co2_GHGreference.###########_surface.txt\")\n",
    "\n",
    "    # check is MBL SURFACE FILE \n",
    "    fname = mblFile.abspath()\n",
    "    is_mbl_surface = False\n",
    "    for start_line, line in enumerate(open(fname)):\n",
    "        if re.findall(\"MBL.*SURFACE\", line):\n",
    "            is_mbl_surface = True\n",
    "        if not line.startswith(\"#\"):\n",
    "            break\n",
    "    if not is_mbl_surface:\n",
    "        raise Exception(\n",
    "            \"The file at the provided url is not an MBL SURFACE file. \"\n",
    "            \"Please check that you have downloaded the correct surface file. \"\n",
    "        )\n",
    "\n",
    "    # TODO:  save name of xCO2 MBL file to log file  \n",
    "    toLog = str(mblFile.relpath())\n",
    "    \n",
    "    return mblFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "543d3225-6348-42b3-a1fe-0292242bf35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xCO2_file(mblFile):\n",
    "\n",
    "    # READ xCO2 data file \n",
    "    # - read header information \n",
    "    # - read dataset into dataframe df\n",
    "    # - convert dates to datetime objects\n",
    "    # - harmonize dims/coordinates to time, latitude\n",
    "\n",
    "    # round latitude degrees to number decimals\n",
    "    ROUND_TO = 2   \n",
    "\n",
    "    fname = mblFile.abspath(); \n",
    "\n",
    "    # read header of datafile \n",
    "    thisFile = open(fname)\n",
    "    header = []\n",
    "    for line in thisFile:\n",
    "        if not line.startswith('#'): \n",
    "            break\n",
    "        else: \n",
    "            header.append(line)\n",
    "    thisFile.close()\n",
    "\n",
    "    # Parse data from header, look for phrases below and split lines at delimiter ':'\n",
    "    # - Product constraints on dataset: dateRange and degLatRange\n",
    "    # - sinLat column headings, convert to degLat \n",
    "\n",
    "    for line in header: \n",
    "\n",
    "        # read data from 'Product Constraints' in header for later error checking \n",
    "        if line.find('Date Range') > -1: \n",
    "            dateRange = line.split(':')\n",
    "            dateRange = dateRange[1].split(',')\n",
    "            dateRange = [x.strip() for x in dateRange]\n",
    "            dateRange = [datetime.datetime.strptime(x, '%Y-%m-%d') for x in dateRange]\n",
    "\n",
    "        if line.find('Degree Latitude Range') > -1 :\n",
    "            degLatRange = line.split(':')\n",
    "            degLatRange = [float(x) for x in degLatRange[1].split(',')]\n",
    "\n",
    "        # get sinLatitude values for data columns, and convert to degreesLatitude\n",
    "        if line.find('Sine of latitude steps') > -1 : \n",
    "            sinLat = line.split(':')\n",
    "            sinLat = [float(x) for x in sinLat[1].split()]\n",
    "            sinLat = np.array(sinLat)\n",
    "            degLat = np.rad2deg(np.arcsin(sinLat))\n",
    "            degLat = np.round(degLat, ROUND_TO)\n",
    "\n",
    "    # Read dataset into a pandas dataframe;  xarray does not handle csv files so well.  \n",
    "    df = pd.read_csv(mblFile, skiprows=len(header), skipinitialspace=True, header=None, sep='\\s+')  \n",
    "\n",
    "    # --- convert dates from year.decimalyear to datetime\n",
    "    # use pyAstronomy.decimalYearGregorianDate to convert to datetime object; give form = str, tuple, or datetime(default)\n",
    "    # have to iterate through items in df, since pyasl does not handle df series properly; insert into first column (ie col 0)\n",
    "    # use 'time' as col label here, as consistent with L Gregor code\n",
    "\n",
    "    times = []\n",
    "    for ii in df[0]: \n",
    "        times.append(pyasl.decimalYearGregorianDate(ii, form='datetime'))\n",
    "    df.insert(0,'time', times)\n",
    "    del(times)\n",
    "\n",
    "    # set the index to time.\n",
    "    df = df.set_index(['time'])\n",
    "\n",
    "\n",
    "    # ---- \n",
    "    # Convert the dataframe to an xarray dataset  - easier to work with for later calculations because the latitudes are listed as a dimension\n",
    "    # Variable names are 'xco2' and 'xco2_uncert' \n",
    "\n",
    "    colNames = df.columns.values.tolist()\n",
    "\n",
    "    ds = df.to_xarray() \n",
    "\n",
    "    # concat uncertainties first to temp dataset ds2\n",
    "    ds2 = xr.concat([ds[ii] for ii in colNames[2::2]], 'lat')\n",
    "    # then concat values back to ds\n",
    "    ds = xr.concat([ds[ii] for ii in colNames[1::2]], 'lat')\n",
    "\n",
    "    ds = ds.assign_coords(coords = {'lat': degLat})\n",
    "    ds = xr.merge([ds, ds2])\n",
    "    ds = ds.rename({1:'xco2', 2:'xco2_uncert'})\n",
    "    ds = ds.transpose()   # transpose coordinates to time, lat\n",
    "    ds = ds.rename({'lat':'latitude'})   # rename dims/coordinates to latitude \n",
    "\n",
    "    ds.assign_attrs({'datasetName': 'xco2'})\n",
    "\n",
    "    #---\n",
    "    # store the dataset to be used within another notebook as dsXco2\n",
    "    dsXco2 = ds\n",
    "\n",
    "    return dsXco2\n",
    "\n",
    "\n",
    "    # TODO\n",
    "    # add attributes to file:  file origin, maybe reference, dateRange and degLatRange \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0bb4e99b-d72f-4009-9824-0148934375aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running main read_xco2.ipynb\n",
      "Stored 'dsXco2' (Dataset)\n",
      "name __main__\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  # allows run without calling this part - incase this notebook is run independently of others.\n",
    "    \n",
    "    print('running main read_xco2.ipynb')\n",
    "    rawDir = './data/raw'\n",
    "    mblFile  = Path(rawDir).files('co2_GHGreference*_surface.txt')[0]\n",
    "    \n",
    "    mblFile = check_xCO2_file(mblFile)\n",
    "    dsXco2 = read_xCO2_file(mblFile)\n",
    "    \n",
    "    %store dsXco2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7fc121-62dd-4b27-8029-ccdf3cb7f881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
